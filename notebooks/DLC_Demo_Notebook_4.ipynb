{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24e3b23a",
   "metadata": {},
   "source": [
    "## Evaluate your network\n",
    "\n",
    "Now that you have trained your network your have to evalute the network (i.e. checking the difference/error between the predicted labels and the actual human labels). This is from the offical documentation:\n",
    "\n",
    "It is important to evaluate the performance of the trained network. This performance is measured by computing the mean average Euclidean error (MAE; which is proportional to the average root mean square error) between the manual labels and the ones predicted by DeepLabCut. The MAE is saved as a comma separated file and displayed for all pairs and only likely pairs (>p-cutoff). This helps to exclude, for example, occluded body parts. One of the strengths of DeepLabCut is that due to the probabilistic output of the scoremap, it can, if sufficiently trained, also reliably report if a body part is visible in a given frame. (see discussions of finger tips in reaching and the Drosophila legs during 3D behavior in [Mathis et al, 2018]). \n",
    "\n",
    "This part needs to be done on the server. So follow the instructions to run a jupyter notebook on the server and do not forget to activate your DEEPLABCUT environment on the server. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9808470e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import deeplabcut"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be83a31b",
   "metadata": {},
   "source": [
    "## Start evaluating\n",
    "This function evaluates a trained model for a specific shuffle/shuffles at a particular state or all the states on the data set (images)\n",
    "and stores the results as .csv file in a subdirectory under **evaluation-results**\n",
    "\n",
    "Make sure you put the correct path of the config file in the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83de41a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_config_file='/home/wallhorn/DLC_Projects/top_view_08_2022-Wallhorn-2022-08-11/config.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8f7af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.evaluate_network(path_config_file, plotting=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe6d6c0",
   "metadata": {},
   "source": [
    "When you open the file \"CombinedEvaluation-results.csv\" it should look like this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a146d18d",
   "metadata": {},
   "source": [
    "| Training iterations | %Training dataset | Shuffle number | Train error(px) | Test error(px) | p-cutoff used | Train error with p-cutoff | Test error with p-cutoff\n",
    "| :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: \n",
    "| 500000 | 95 | 1 | 2.3 | 4.64 | 0.6 | 2.3 | 4.64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2794f2",
   "metadata": {},
   "source": [
    "Important is the Test error. This should not be to high. In this case around 5 pixels is very good since the resolution of the images/videos is not that high. Within that folder there is another subfolder. There you can find the picture with the manual labels and the predicted labels. If the results are good enough you can proceed to the DLC_Demo_Notebook_5. If not you have to gob back and label new picture and/or training for more iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9dbdf87",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
