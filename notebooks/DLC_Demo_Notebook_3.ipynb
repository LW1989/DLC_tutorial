{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RK255E7YoEIt"
   },
   "source": [
    "## Submitting a Slurm Job\n",
    "\n",
    "Now that you created the training data set you are ready to finally train your network. For this you need a lot of GPU power. Therefore, all these parts are down on the HPC of the University. This server is managed by a framework called “Slurm”\n",
    "\n",
    "(https://slurm.schedmd.com/documentation.html). In simplified terms: It manages the different requests for processing time on the CPU as well as the GPU cluster. You submit a job that is put into a queue. Afterwards you can log out and check later that day or the next day if your job has already finished. You can interact with it through the terminal on the server or through the jupyter notebook. For the latter option you will need to install slurm-magic (https://github.com/NERSC/slurm-magic). \n",
    "\n",
    "To do that connect to the server via PuTTY/Terminal and within your base environment type:\n",
    "\n",
    "`pip install git+https://github.com/NERSC/slurm-magic.git`\n",
    "\n",
    "Note: For whatever reason (I do not have any idea why) the following steps need to be done within your base environment and NOT within the DEEPLABCUT environment. If you are still in your DEEPLABCUT environment type: conda activate base\n",
    "\n",
    "Before you can execute this batch script you need to transfer the py_scripts folder from the tutorial directory to the server, the same way you did with the project folder (i.e. with WinSCP/Cyberduck)\n",
    "\n",
    "The submitting of jobs is done by executing batch scripts. We will do that from within the jupyter notebook. these will look something like that:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Uoz9mdPoEIy"
   },
   "source": [
    "Important: Go to the py_script folder and open the training_script.py with a text editor (can be done wihtin WinSCP/Cyberduck).\n",
    "\n",
    "It should look like that:\n",
    "\n",
    "`import deeplabcut\n",
    " ProjectFolderName = 'OpenField-Wallhorn-2022-08-15'\n",
    " path_config_file = '/home/wallhorn/DLC_Projects/top_view_08_2022-Wallhorn-2022-08-11/config.yaml'\n",
    " deeplabcut.train_network(path_config_file, displayiters=1000,saveiters=50000, maxiters=500000)`\n",
    " \n",
    " change the path of the config file to the path of your config file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext slurm_magic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First you should check how many other Jobs there are waiting to be processed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%squeue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you are almost ready to run the batch script. But first you have to make sure the script knows where the py-script is located. Check if this path is correct:\n",
    "\n",
    "`cd /home/wallhorn/DLC_Projects/py_scripts`\n",
    "\n",
    "And check if this runs the correct script:\n",
    "\n",
    "`srun python3 training_script.py`\n",
    "\n",
    "\n",
    "Also look at this line: \n",
    "\n",
    "`#SBATCH --output=/home/wallhorn/DLC_Projects/job_reports/%j.out`\n",
    "\n",
    "This is the path where Slurm is saving the job report. Edit this to a path of your chosing. It is important to check these reports, to see if everything worked. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sbatch\n",
    "#!/bin/bash\n",
    "#\n",
    "#SBATCH --job-name=DLC_training\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --cpus-per-task=48\n",
    "#SBATCH --output=/home/wallhorn/DLC_Projects/job_reports/%j.out\n",
    "\n",
    "\n",
    "module load cuda\n",
    "module load anaconda\n",
    "\n",
    "source /hpc/opt/apps/Anaconda/3-2021.11/etc/profile.d/conda.sh\n",
    "conda init bash\n",
    "\n",
    "conda activate DEEPLABCUT\n",
    "\n",
    "export LD_LIBRARY_PATH=\"$CONDA_PREFIX/lib\"\n",
    "cd /home/wallhorn/DLC_Projects/py_scripts\n",
    "\n",
    "srun python3 training_script.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now your job is submitted and you can check if it is in the queue by executing the following cell. You can also go the folder where the job reports are being saved and open the job report with a text editor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%squeue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When your job is done continue with DLC_Demo_Notebook_4"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Demo-yourowndata.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
